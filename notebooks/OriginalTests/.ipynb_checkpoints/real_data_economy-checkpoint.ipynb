{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sequential_causal_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygraphviz\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msequential_causal_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (extract_data_streams_from_multivariate_time_series_list,\n\u001b[1;32m     21\u001b[0m                                                      sequentially_sample_model,\n\u001b[1;32m     22\u001b[0m                                                      powerset)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msequential_intervention_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (create_n_dimensional_intervention_grid,\n\u001b[1;32m     25\u001b[0m                                                get_interventional_grids,\n\u001b[1;32m     26\u001b[0m                                                make_sequential_intervention_dictionary)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexperiments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimal_sequence_of_interventions, optimise_one_time_step\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sequential_causal_functions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "sys.path.append(\"..\")\n",
    "from src.utilities import select_sample\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "\n",
    "from graph_functions import generate_CGM\n",
    "from networkx import nx_agraph\n",
    "from networkx.drawing.nx_agraph import write_dot\n",
    "from GPy.kern import RBF\n",
    "from GPy.models.gp_regression import GPRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import pygraphviz\n",
    "import graphviz\n",
    "from sequential_causal_functions import (extract_data_streams_from_multivariate_time_series_list,\n",
    "                                                     sequentially_sample_model,\n",
    "                                                     powerset)\n",
    "\n",
    "from sequential_intervention_functions import (create_n_dimensional_intervention_grid,\n",
    "                                               get_interventional_grids,\n",
    "                                               make_sequential_intervention_dictionary)\n",
    "\n",
    "from experiments import optimal_sequence_of_interventions, optimise_one_time_step\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gp(\n",
    "    x, y, lengthscale=1.0, variance=1.0, noise_var=1.0, ard=False, n_restart=10, seed: int = 0,\n",
    "):\n",
    "    kernel = RBF(x.shape[1], ARD=ard, lengthscale=lengthscale, variance=variance)\n",
    "    model = GPRegression(X=x, Y=y, kernel=kernel, noise_var=noise_var)\n",
    "    model.optimize_restarts(n_restart, verbose=False, robust=True)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 3 # Required timesteps\n",
    "graph_view = generate_CGM(0,T-1, spatial_connection_topo='dependent', verbose=True) # Base topology\n",
    "graph_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_view.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_view_modified = 'digraph { rankdir=LR; F_0 -> Z_0; X_0 -> Y_0; X_0 -> Z_0; Z_0 -> Y_0;  F_1 -> Z_1; X_1 -> Y_1; X_1 -> Z_1; Z_1 -> Y_1; F_2 -> Z_2; X_2 -> Y_2; X_2 -> Z_2; Z_2 -> Y_2; X_0 -> X_1; Y_0 -> Y_1; Z_0 -> Z_1; X_1 -> X_2; Y_1 -> Y_2; Z_1 -> Z_2; { rank=same; X_0 Z_0 Y_0 } { rank=same; X_1 Z_1 Y_1 } { rank=same; X_2 Z_2 Y_2 }  }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DOT string to NetworkX object\n",
    "Graph = nx_agraph.from_agraph(pygraphviz.AGraph(graph_view_modified))\n",
    "Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dot(Graph, \"../src/graphs/graph_view_real.dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../src/graphs/graph_view_real.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP = pd.read_csv('../data/economic_data/GDP.csv')\n",
    "M3 = pd.read_csv('../data/economic_data/M3.csv')\n",
    "INF = pd.read_csv('../data/economic_data/INF.csv')\n",
    "TAX = pd.read_csv('../data/economic_data/TAX.csv')\n",
    "UN = pd.read_csv('../data/economic_data/UN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP = GDP[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "M3 = M3[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "INF = INF[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "TAX = TAX[[\"LOCATION\", \"TIME\", \"Value\"]]\n",
    "UN = UN[[\"LOCATION\", \"TIME\", \"Value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = pd.merge(GDP, M3,  how='left', on=['LOCATION','TIME'])\n",
    "new_df2 = pd.merge(GDP, INF,  how='left', on=['LOCATION','TIME'])\n",
    "new_df3 = pd.merge(new_df2, TAX,  how='left', on=['LOCATION','TIME'])\n",
    "new_df4 = pd.merge(new_df3, UN,  how='left', on=['LOCATION','TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df4.columns = ['LOC', 'TIME', 'GDP', 'M3', 'INF', 'TAX', 'UN']\n",
    "new_df4.columns = ['LOC', 'TIME', 'GDP', 'INF', 'TAX', 'UN']\n",
    "data = new_df4[new_df4['TIME'] > 2008]\n",
    "data = data[data['TIME'] < 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = []\n",
    "for i in range(10):\n",
    "    time = 2009 + i\n",
    "    country_list.append(list(data[data['TIME'] == time]['LOC']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data['LOC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['M3%'] = np.nan\n",
    "data['GDP%'] = np.nan\n",
    "data['log_U'] = np.nan\n",
    "data['TAX%'] = np.nan\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    if i > 0:\n",
    "        # Monetary policy\n",
    "        #perc_change_M3 = ((list(data['M3'])[i] \n",
    "        #                 - list(data['M3'])[i-1])/list(data['M3'])[i-1])*100\n",
    "        \n",
    "        #perc_change_M3 = list(data['M3'])[i]\n",
    "        \n",
    "        # Z\n",
    "        perc_change_GDP = ((list(data['GDP'])[i] \n",
    "                           - list(data['GDP'])[i-1])/list(data['GDP'])[i-1])*100\n",
    "        #perc_change_GDP = list(data['GDP'])[i] \n",
    "        \n",
    "        # Fiscal policy\n",
    "        perc_change_tax = ((list(data['TAX'])[i]*list(data['GDP'])[i] \n",
    "                           - list(data['TAX'])[i-1]*\n",
    "                            list(data['GDP'])[i-1])/(list(data['TAX'])[i-1]*list(data['GDP'])[i-1]))*100\n",
    "        #perc_change_tax = list(data['TAX'])[i]*list(data['GDP'])[i] \n",
    "        \n",
    "        # Y\n",
    "        log_U = list(data['UN'])[i] #np.log(list(data['UN'])[i])\n",
    "        \n",
    "        \n",
    "        #data.at[i,'M3%'] = perc_change_M3\n",
    "        data.at[i,'GDP%'] = perc_change_GDP\n",
    "        data.at[i,'log_U'] = log_U\n",
    "        data.at[i,'TAX%'] = perc_change_tax\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data = data[['LOC', 'TIME', 'M3%', 'GDP%', 'log_U', 'TAX%', 'INF']]\n",
    "extracted_data = data[['LOC', 'TIME', 'GDP%', 'log_U', 'TAX%', 'INF']]\n",
    "extracted_data = extracted_data.dropna()[extracted_data['TIME'] != 2009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#extracted_data[['M3%', 'GDP%', 'log_U', 'TAX%', 'INF']] = preprocessing.normalize(extracted_data[['M3%', 'GDP%', 'log_U', 'TAX%', 'INF']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data = extracted_data[extracted_data['LOC'] != 'TUR'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data = extracted_data[extracted_data['LOC'] != 'MEX'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.asarray(extracted_data[['GDP%', 'TIME', 'LOC']].pivot(index = 'LOC', columns='TIME'))\n",
    "Y = np.asarray(extracted_data[['log_U', 'TIME', 'LOC']].pivot(index = 'LOC', columns='TIME'))\n",
    "X = np.asarray(extracted_data[['INF', 'TIME', 'LOC']].pivot(index = 'LOC', columns='TIME'))\n",
    "F = np.asarray(extracted_data[['TAX%', 'TIME', 'LOC']].pivot(index = 'LOC', columns='TIME'))\n",
    "#M = np.asarray(extracted_data[['M3%', 'TIME', 'LOC']].pivot(index = 'LOC', columns='TIME'))\n",
    "date = np.asarray(list(extracted_data['TIME']))\n",
    "observational_samples = {'Z':Z, 'Y':Y, 'X':X, 'F':F}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Countries: \\n', len(country_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit functions at t=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametric = False\n",
    "liner_type = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vector = np.tile(np.linspace(0, 8, 9), 11)[:,np.newaxis]\n",
    "if parametric is False:\n",
    "    model_F = fit_gp(time_vector,  np.hstack(observational_samples['F'])[:,np.newaxis])\n",
    "\n",
    "    model_X = fit_gp(time_vector,  np.hstack(observational_samples['X'])[:,np.newaxis])\n",
    "\n",
    "    model_Z = fit_gp(np.hstack((np.hstack(observational_samples['X'])[:,np.newaxis], \n",
    "                             np.hstack(observational_samples['F'])[:,np.newaxis])),  \n",
    "                             np.hstack(observational_samples['Z'])[:,np.newaxis])\n",
    "    \n",
    "    model_Y = fit_gp(np.hstack((observational_samples['X'][:,0][:,np.newaxis], \n",
    "                             observational_samples['Z'][:,0][:,np.newaxis])),  \n",
    "                             observational_samples['Y'][:,0][:,np.newaxis])\n",
    "elif liner_type:\n",
    "    model_F = LinearRegression().fit(time_vector, np.hstack(observational_samples['F'])[:,np.newaxis])\n",
    "    model_X = LinearRegression().fit(np.hstack(observational_samples['M'])[:,np.newaxis],  \n",
    "                  np.hstack(observational_samples['X'])[:,np.newaxis])\n",
    "\n",
    "    model_Z = LinearRegression().fit(np.hstack((np.hstack(observational_samples['X'])[:,np.newaxis], \n",
    "                             np.hstack(observational_samples['F'])[:,np.newaxis])),  \n",
    "                             np.hstack(observational_samples['Z'])[:,np.newaxis])\n",
    "\n",
    "    model_Y = LinearRegression().fit(np.hstack((np.hstack(observational_samples['X'])[:,np.newaxis], \n",
    "                             np.hstack(observational_samples['Z'])[:,np.newaxis])),  \n",
    "                             np.hstack(observational_samples['Y'])[:,np.newaxis])    \n",
    "else:\n",
    "    numpy.polyfit(numpy.log(x), y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_0 = {'Z': model_Z, 'Y': model_Y, 'X':model_X, 'F': model_F}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit functions for t=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for AR models\n",
    "X_AR = []\n",
    "Z_AR = []\n",
    "Y_AR = []\n",
    "for i in range(observational_samples['X'].shape[0]):\n",
    "    #X_AR.append(np.transpose(np.vstack((observational_samples['X'][i][:-1],  \n",
    "    #                                    observational_samples['M'][i][1:],\n",
    "    #                                    observational_samples['X'][i][1:]))))\n",
    "    \n",
    "    X_AR.append(np.transpose(np.vstack((observational_samples['X'][i][:-1],\n",
    "                                        observational_samples['X'][i][1:]))))\n",
    "        \n",
    "    \n",
    "    Z_AR.append(np.transpose(np.vstack((observational_samples['Z'][i][:-1],\n",
    "                                        observational_samples['X'][i][1:],\n",
    "                                        observational_samples['F'][i][1:],\n",
    "                                        observational_samples['Z'][i][1:]))))\n",
    "    \n",
    "    \n",
    "    Y_AR.append(np.transpose(np.vstack((observational_samples['Y'][i][:-1],\n",
    "                                        observational_samples['Z'][i][1:],\n",
    "                                        observational_samples['X'][i][1:],\n",
    "                                        observational_samples['Y'][i][1:]))))\n",
    "\n",
    "X_AR = np.vstack(X_AR)\n",
    "Z_AR = np.vstack(Z_AR)\n",
    "Y_AR = np.vstack(Y_AR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parametric is False:\n",
    "    model_X_t = fit_gp(X_AR[:, :-1], X_AR[:, -1][:,np.newaxis])\n",
    "    model_Z_t = fit_gp(Z_AR[:, :-1], Z_AR[:, -1][:,np.newaxis])\n",
    "    model_Y_t = fit_gp(Y_AR[:, :-1], Y_AR[:, -1][:,np.newaxis])\n",
    "else:\n",
    "    model_X_t = LinearRegression().fit(X_AR[:, :-1], X_AR[:, -1][:,np.newaxis])\n",
    "    model_Z_t = LinearRegression().fit(Z_AR[:, :-1], Z_AR[:, -1][:,np.newaxis])\n",
    "    model_Y_t = LinearRegression().fit(Y_AR[:, :-1], Y_AR[:, -1][:,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_t = {'Z': model_Z_t, 'Y': model_Y_t, 'X': model_X_t, 'F': model_F}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parametric is False:\n",
    "    model_Inf_U = fit_gp(np.hstack(observational_samples['X'])[:,np.newaxis],  \n",
    "                             np.hstack(observational_samples['Y'])[:,np.newaxis])\n",
    "    \n",
    "    model_Inf_U = fit_gp(observational_samples['X'][:,0][:,np.newaxis],  \n",
    "                        observational_samples['Y'][:,0][:,np.newaxis])\n",
    "    \n",
    "    model_Inf_U.plot()\n",
    "else:\n",
    "    model_Inf_U = LinearRegression().fit(np.hstack(observational_samples['X'])[:,np.newaxis],  \n",
    "                                 np.hstack(observational_samples['Y'])[:,np.newaxis])    \n",
    "\n",
    "    plt.plot(np.hstack(observational_samples['X']), \n",
    "             model_Inf_U.predict(np.hstack(observational_samples['X'])[:,np.newaxis]))\n",
    "\n",
    "    plt.scatter(np.hstack(observational_samples['X']), np.hstack(observational_samples['Y']))\n",
    "    plt.title('Inflation on Unemployment')\n",
    "    plt.xlabel('Inflation')\n",
    "    plt.ylabel('Unemployment')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parametric is False:\n",
    "#     model_GDP_U = fit_gp(np.hstack(observational_samples['Z'])[:,np.newaxis],  \n",
    "#                              np.hstack(observational_samples['Y'])[:,np.newaxis])\n",
    "    \n",
    "#     model_GDP_U.plot()\n",
    "    \n",
    "        \n",
    "    model_GDP_U = fit_gp(observational_samples['Z'][:,0][:,np.newaxis],  \n",
    "                          observational_samples['Y'][:,0][:,np.newaxis])\n",
    "    \n",
    "    model_GDP_U.plot()\n",
    "else:\n",
    "    model_GDP_U = LinearRegression().fit(np.hstack(observational_samples['Z'])[:,np.newaxis],  \n",
    "                             np.hstack(observational_samples['Y'])[:,np.newaxis])    \n",
    "\n",
    "    plt.plot(np.hstack(observational_samples['Z']), \n",
    "             model_GDP_U.predict(np.hstack(observational_samples['Z'])[:,np.newaxis]))\n",
    "\n",
    "    plt.scatter(np.hstack(observational_samples['Z']), np.hstack(observational_samples['Y']))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in range(8):\n",
    "#     model_GDP_U = LinearRegression().fit(observational_samples['Z'][:,t][:,np.newaxis],  \n",
    "#                              observational_samples['Y'][:,t][:,np.newaxis])    \n",
    "\n",
    "#     plt.plot(observational_samples['Z'][:,t], \n",
    "#              model_GDP_U.predict(observational_samples['Z'][:,t][:,np.newaxis]))\n",
    "\n",
    "#     plt.scatter(observational_samples['Z'][:,t], observational_samples['Y'][:,t])\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parametric is False:\n",
    "    model_Inf_GDP = fit_gp(np.hstack(observational_samples['X'])[:,np.newaxis],  \n",
    "                             np.hstack(observational_samples['Z'])[:,np.newaxis])\n",
    "    \n",
    "    model_Inf_GDP = fit_gp(observational_samples['X'][:,0][:,np.newaxis],  \n",
    "                        observational_samples['Z'][:,0][:,np.newaxis])\n",
    "    \n",
    "    model_Inf_GDP.plot()\n",
    "\n",
    "\n",
    "    #plt.scatter(np.hstack(observational_samples['X']), np.hstack(observational_samples['Y']))\n",
    "    plt.title('Inflation on GDP')\n",
    "    plt.xlabel('Inflation')\n",
    "    plt.ylabel('GDP')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is Inflation, Z is GDP\n",
    "model_X_t.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is Inflation, Z is GDP\n",
    "X, Z = np.meshgrid(np.linspace(-1., 6, 100)[:, np.newaxis], \n",
    "                   np.linspace(-3, 9, 100)[:, np.newaxis])\n",
    "if parametric is False:\n",
    "    Y_vals = model_Y.predict(np.transpose(np.vstack((np.hstack(X), np.hstack(Z)))))[0]\n",
    "else:\n",
    "    Y_vals = model_Y.predict(np.transpose(np.vstack((np.hstack(X), np.hstack(Z)))))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(X, Z, Y_vals.reshape(100, 100))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Real_SEM:\n",
    "    def __init__(self, functions_0, functions_t):\n",
    "        self.functions_0 = functions_0\n",
    "        self.functions_t = functions_t\n",
    "\n",
    "    def static(self):\n",
    "\n",
    "        F = lambda noise, time, sample: self.functions_0['F'].predict(time*np.ones((1,1)))[0]\n",
    "        \n",
    "        X = lambda noise, time, sample: self.functions_0['X'].predict(time*np.ones((1,1)))[0]\n",
    "        \n",
    "        Z = lambda noise, time, sample: self.functions_0['Z'].predict(np.transpose(np.vstack((sample['X'][time]\n",
    "                                                                                              *np.ones((1,1)), \n",
    "                                                                              sample['F'][time]*np.ones((1,1))))))[0]\n",
    "\n",
    "        Y = lambda noise, time, sample: self.functions_0['Y'].predict(np.transpose(np.vstack((sample['X'][time]\n",
    "                                                                                              *np.ones((1,1)), \n",
    "                                                                              sample['Z'][time]*np.ones((1,1))))))[0]\n",
    "        \n",
    "        return OrderedDict([(\"F\", F), (\"X\", X), (\"Z\", Z), (\"Y\", Y)])\n",
    "\n",
    "    def dynamic(self):\n",
    "\n",
    "        F = lambda noise, time, sample: self.functions_t['F'].predict(time*np.ones((1,1)))[0]\n",
    "        \n",
    "        X = lambda noise, time, sample: self.functions_t['X'].predict(np.transpose(sample['X'][time-1]*\n",
    "                                                                                   np.ones((1,1))))[0]\n",
    "        \n",
    "        Z = lambda noise, time, sample: self.functions_t['Z'].predict(np.transpose(np.vstack((sample['Z'][time-1]\n",
    "                                                                                              *np.ones((1,1)), \n",
    "                                                                                sample['X'][time]*np.ones((1,1)), \n",
    "                                                                                sample['F'][time]*np.ones((1,1))))))[0]\n",
    "        \n",
    "        Y = lambda noise, time, sample: self.functions_t['Y'].predict(np.transpose(np.vstack((sample['Y'][time-1]\n",
    "                                                                                              *np.ones((1,1)), \n",
    "                                                                                sample['Z'][time]*np.ones((1,1)),\n",
    "                                                                                sample['X'][time]*np.ones((1,1))))))[0]\n",
    "\n",
    "        return OrderedDict([(\"F\", F), (\"X\", X), (\"Z\", Z), (\"Y\", Y)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sem_real_hat(emission_fncs: dict, transition_fncs: dict) -> classmethod:\n",
    "\n",
    "    class semhat:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def static(self, moment: int):\n",
    "            assert moment in [0, 1], moment\n",
    "\n",
    "            F = lambda noise: noise\n",
    "            \n",
    "#             X = lambda t, emit_input_var, sample: emission_fncs[t][emit_input_var].predict(\n",
    "#                 select_sample(sample, emit_input_var, t)\n",
    "#             )[moment]\n",
    "            \n",
    "            X = lambda noise: noise\n",
    "            \n",
    "            Z = lambda t, emit_input_var, sample: emission_fncs[t][emit_input_var].predict(\n",
    "                select_sample(sample, emit_input_var, t)\n",
    "            )[moment]\n",
    "            \n",
    "            Y = lambda t, emit_input_var, sample: emission_fncs[t][emit_input_var].predict(\n",
    "                select_sample(sample, emit_input_var, t)\n",
    "            )[moment]\n",
    "            return OrderedDict([(\"F\", F), (\"X\", X), (\"Z\", Z), (\"Y\", Y)])\n",
    "        \n",
    "        def dynamic(self, moment: int):\n",
    "            assert moment in [0, 1], moment\n",
    "\n",
    "            F = lambda noise: noise\n",
    "\n",
    "            X = lambda t, transfer_input_vars, emit_input_vars, sample: transition_fncs[transfer_input_vars].predict(\n",
    "                select_sample(sample, transfer_input_vars, t - 1)\n",
    "            )[moment]\n",
    "\n",
    "            Z = lambda t, transfer_input_vars, emit_input_vars, sample: transition_fncs[transfer_input_vars].predict(\n",
    "                select_sample(sample, transfer_input_vars, t - 1)\n",
    "            )[moment]\n",
    "\n",
    "            Y = (\n",
    "                lambda t, transfer_input_vars, emit_input_vars, sample: transition_fncs[transfer_input_vars].predict(\n",
    "                    select_sample(sample, transfer_input_vars, t - 1)\n",
    "                )[moment]\n",
    "            )\n",
    "\n",
    "            return OrderedDict([(\"F\", F), (\"X\", X), (\"Z\", Z), (\"Y\", Y)])\n",
    "\n",
    "    return semhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEM = Real_SEM(functions_0, functions_t)\n",
    "initial_structural_equation_model = SEM.static()\n",
    "structural_equation_model = SEM.dynamic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_domain = {'F':[-.3, 10],'M':[-2., 20.], 'X':[-2., 6.]}\n",
    "intervention_domain = {'F':[-.3, 10], 'X':[-2., 6.]}\n",
    "exploration_sets = list(powerset(['F', 'X']))  \n",
    "n_to_compute = 100\n",
    "interventional_grids = get_interventional_grids(exploration_sets, intervention_domain, size_intervention_grid = n_to_compute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute optimal intervention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_s_values, best_s_sequence, best_objective_values, y_stars_all, optimal_interventions, all_CE = \\\n",
    "optimal_sequence_of_interventions(exploration_sets, \n",
    "                                  interventional_grids, \n",
    "                                  initial_structural_equation_model,\n",
    "                                  structural_equation_model,\n",
    "                                  Graph,\n",
    "                                  T=T, \n",
    "                                  variables = ['X', 'Z', 'Y', 'F', 'M'], \n",
    "                                  task = 'min')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best intervention set:', best_s_sequence)\n",
    "print('Best intervention values:', best_s_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(T):\n",
    "    print(\"  \")\n",
    "    print('t:', t)\n",
    "    for setx in exploration_sets:\n",
    "        print('set:', setx)\n",
    "        print('Best value :', np.min(all_CE[t][setx]))\n",
    "        print('Best intervention value :', interventional_grids[setx][np.argmin(all_CE[t][setx])])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in range(T):\n",
    "    print('t', t)\n",
    "    \n",
    "#     print('M')\n",
    "#     plt.plot(interventional_grids[('M',)], all_CE[t][('M',)])\n",
    "#     plt.show()\n",
    "    \n",
    "    print('X')\n",
    "    plt.plot(interventional_grids[('X',)], all_CE[t][('X',)])\n",
    "    plt.show()\n",
    "    \n",
    "    print('F')\n",
    "    plt.plot(interventional_grids[('F',)], all_CE[t][('F',)])\n",
    "    plt.show()\n",
    "    \n",
    "    #X, Y = np.meshgrid(interventional_grids[('F',)], interventional_grids[('M',)])\n",
    "    X, Y = np.meshgrid(interventional_grids[('F',)], interventional_grids[('X',)])\n",
    "    #vals = np.asarray(all_CE[t][('F','M')])\n",
    "    vals = np.asarray(all_CE[t][('F','X')])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.plot_surface(X, Y, vals.reshape(n_to_compute, n_to_compute))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT = []\n",
    "optimal_assigned_blankets = [None]*T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanket, _ = make_sequential_intervention_dictionary(Graph)\n",
    "blanket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import calculate_best_intervention_and_effect\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blanket, _ = make_sequential_intervention_dictionary(Graph)\n",
    "for t in range(T):\n",
    "    new_blanket, true_causal_effect  = calculate_best_intervention_and_effect(\n",
    "                                          static_sem=initial_structural_equation_model,\n",
    "                                          dynamic_sem=structural_equation_model,\n",
    "                                          exploration_sets=exploration_sets,\n",
    "                                          interventional_grids=interventional_grids,\n",
    "                                          time=t,\n",
    "                                          intervention_domain=intervention_domain,\n",
    "                                          blanket=deepcopy(blanket),\n",
    "                                          T=T,\n",
    "                                          plot = True)\n",
    "    if t < T-1: \n",
    "        optimal_assigned_blankets[t+1] = new_blanket\n",
    "    \n",
    "    blanket = new_blanket\n",
    "    \n",
    "    GT.append(true_causal_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# DCBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from dcbo_base import BaseClassDCBO\n",
    "from dcbo import DCBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset_obs_data = deepcopy(observational_samples)\n",
    "for var in subset_obs_data.keys():\n",
    "    subset_obs_data[var] = subset_obs_data[var][:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DCBO_input_params = {\n",
    "    \"graph\": Graph,\n",
    "    \"sem\": Real_SEM,\n",
    "    \"make_sem_hat\": make_sem_real_hat,\n",
    "    \"observational_samples\": subset_obs_data,\n",
    "    \"intervention_domain\": intervention_domain,\n",
    "    \"exploration_sets\": exploration_sets,\n",
    "    \"interventional_samples\": None,  \n",
    "    \"number_of_trials\": 20,\n",
    "    \"ground_truth\": GT,\n",
    "    \"debug_mode\": False,\n",
    "    \"optimal_assigned_blankets\": optimal_assigned_blankets, \n",
    "    \"num_anchor_points\": 200,\n",
    "    \"sample_anchor_points\": True,\n",
    "    \"seed_anchor_points\": 1,\n",
    "    \"args_sem\": [functions_0, functions_t],\n",
    "    \"manipulative_variables\": ['F', 'X'],\n",
    "    \"hp_i_prior\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dcbo = DCBO(**DCBO_input_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "country_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dcbo.run_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(T, figsize=(10,13), sharex=True)\n",
    "for i in range(T):\n",
    "    ax[i].plot(dcbo.optimal_outcome_values_during_trials[i][1:],lw=3,label='DCBO')\n",
    "    ax[i].hlines(best_objective_values[i],0, 10,'r',ls='--',lw=5,alpha=0.2,label='Ground truth at $t={}$'.format(i))\n",
    "    ax[i].grid(True)\n",
    "    ax[i].legend(ncol=1, fontsize=\"medium\", loc=\"lower center\", frameon=False, bbox_to_anchor=(1.25, 0.4))\n",
    "\n",
    "ax[2].set_xlabel(r\"Opt. cycles\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# CBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from cbo import CBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CBO_input_params = {\n",
    "    \"graph\": Graph,\n",
    "    \"sem\": Real_SEM,\n",
    "    \"make_sem_hat\": make_sem_real_hat,\n",
    "    \"observational_samples\": subset_obs_data,\n",
    "    \"intervention_domain\": intervention_domain,\n",
    "    \"exploration_sets\": exploration_sets,\n",
    "    \"interventional_samples\": None,  \n",
    "    \"number_of_trials\": 20,\n",
    "    \"ground_truth\": GT,\n",
    "    \"debug_mode\": False,\n",
    "    \"optimal_assigned_blankets\": optimal_assigned_blankets, \n",
    "    \"num_anchor_points\": 200,\n",
    "    \"sample_anchor_points\": True,\n",
    "    \"seed_anchor_points\": 1,\n",
    "    \"args_sem\": [functions_0, functions_t],\n",
    "    \"manipulative_variables\": ['F', 'X'],\n",
    "    \"hp_i_prior\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cbo = CBO(**CBO_input_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cbo.run_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(T, figsize=(10,13), sharex=True)\n",
    "for i in range(T):\n",
    "    ax[i].plot(cbo.optimal_outcome_values_during_trials[i][1:],lw=2,label='CBO')\n",
    "    ax[i].plot(dcbo.optimal_outcome_values_during_trials[i][1:],lw=3,label='DCBO')\n",
    "    ax[i].hlines(best_objective_values[i],0, 10,'r',ls='--',lw=5,alpha=0.2,label='Ground truth at $t={}$'.format(i))\n",
    "    #ax[i].set_ylabel(r\"$\\mathbb{{E}}[{}_{} \\mid \\textrm{{do}}(...),\\textrm{{did}}(...) ]$\".format(\"Y\", i))\n",
    "    #ax[i].set_xlim(0, len(cbo.trial_type[1]))\n",
    "    ax[i].grid(True)\n",
    "    ax[i].legend(ncol=1, fontsize=\"medium\", loc=\"lower center\", frameon=False, bbox_to_anchor=(1.25, 0.4))\n",
    "ax[2].set_xlabel(r\"Opt. cycles\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ABO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from abo import ABO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trials_ABO = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ABO_input_params = {\n",
    "    \"graph\": Graph,\n",
    "    \"sem\": Real_SEM,\n",
    "    \"observational_samples\": subset_obs_data,\n",
    "    \"intervention_domain\":intervention_domain,\n",
    "    \"interventional_samples\": None,   \n",
    "    \"number_of_trials\": trials_ABO,\n",
    "    \"optimal_assigned_blankets\": optimal_assigned_blankets,\n",
    "    \"sample_anchor_points\": True,\n",
    "    \"seed_anchor_points\": 0,\n",
    "    \"args_sem\": [functions_0, functions_t],\n",
    "    \"manipulative_variables\": ['F', 'X'],\n",
    "    \"hp_i_prior\": False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "abo = ABO(**ABO_input_params)\n",
    "abo.run_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(T, figsize=(10,13), sharex=True)\n",
    "for i in range(T):\n",
    "    ax[i].plot(abo.optimal_outcome_values_during_trials[i][1:],lw=3,label='DCBO')\n",
    "    ax[i].hlines(best_objective_values[i],0, 10,'r',ls='--',lw=5,alpha=0.2,label='Ground truth at $t={}$'.format(i))\n",
    "    ax[i].grid(True)\n",
    "    ax[i].legend(ncol=1, fontsize=\"medium\", loc=\"lower center\", frameon=False, bbox_to_anchor=(1.25, 0.4))\n",
    "\n",
    "ax[2].set_xlabel(r\"Opt. cycles\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# BO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from bo import BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trials_BO = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "BO_input_params = {\n",
    "    \"graph\": Graph,\n",
    "    \"sem\": Real_SEM,\n",
    "    \"observational_samples\": subset_obs_data,\n",
    "    \"intervention_domain\": intervention_domain,\n",
    "    \"interventional_samples\":None,   \n",
    "    \"number_of_trials\": trials_BO,\n",
    "    \"optimal_assigned_blankets\": optimal_assigned_blankets,\n",
    "    \"sample_anchor_points\": True,\n",
    "    \"seed_anchor_points\": 0,\n",
    "    \"args_sem\": [functions_0, functions_t],\n",
    "    \"manipulative_variables\": ['F', 'X'],\n",
    "    \"hp_i_prior\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bo = BO(**BO_input_params)\n",
    "bo.run_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lim_value = 20\n",
    "fig, ax = plt.subplots(T, figsize=(10,13), sharex=True)\n",
    "for i in range(T):\n",
    "    ax[i].plot(([0] + list(np.cumsum(bo.per_trial_cost[i])))[:trials_BO-1], \n",
    "               bo.optimal_outcome_values_during_trials[i][1:],lw=2,label='BO')\n",
    "    \n",
    "    ax[i].plot(([0] + list(np.cumsum(abo.per_trial_cost[i])))[:trials_ABO-1], \n",
    "               abo.optimal_outcome_values_during_trials[i][1:],lw=2,label='ABO')\n",
    "    ax[i].plot(dcbo.optimal_outcome_values_during_trials[i][1:],lw=3,label='DCBO')\n",
    "    ax[i].plot(cbo.optimal_outcome_values_during_trials[i][1:],lw=2,label='CBO')\n",
    "    ax[i].hlines(best_objective_values[i],0, lim_value,'r',ls='--',lw=5,alpha=0.2,label='Ground truth at $t={}$'.format(i))\n",
    "    ax[i].grid(True)\n",
    "    ax[i].legend(ncol=1, fontsize=\"medium\", loc=\"lower center\", frameon=False, bbox_to_anchor=(1.25, 0.4))\n",
    "\n",
    "ax[2].set_xlabel(r\"Opt. cycles\")\n",
    "ax[2].set_xlim(0,lim_value)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for t in range(T):\n",
    "    print(' dcbo', dcbo.optimal_outcome_values_during_trials[t][-1])\n",
    "    print(' cbo', cbo.optimal_outcome_values_during_trials[t][-1])\n",
    "    print('  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import plot_expected_opt_curve, plot_opt_curve\n",
    "from experiments import run_methods_replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_replicates = 1\n",
    "n_trials = 20\n",
    "number_of_trials_BO_ABO = 20\n",
    "folder = 'economic_data/no_blanket'\n",
    "methods_list = ['DCBO', 'CBO', 'ABO', 'BO']\n",
    "sample_anchor_points = True\n",
    "cost_list = [1]\n",
    "for cost in cost_list:\n",
    "    results = run_methods_replicates(Graph, \n",
    "                                     Real_SEM, \n",
    "                                     make_sem_real_hat, \n",
    "                                     intervention_domain, \n",
    "                                     methods_list = methods_list,\n",
    "                                     obs_samples = subset_obs_data,\n",
    "                                     ground_truth = GT,\n",
    "                                     exploration_sets = exploration_sets,\n",
    "                                     total_timesteps = T,\n",
    "                                     reps = n_replicates,\n",
    "                                     number_of_trials = n_trials, \n",
    "                                     number_of_trials_BO_ABO = number_of_trials_BO_ABO,\n",
    "                                     n_restart = 1,\n",
    "                                     save_data = True,\n",
    "                                     n_obs = None,                                    \n",
    "                                     hp_i_prior = True,\n",
    "                                     debug_mode = False,\n",
    "                                     folder = folder,\n",
    "                                     optimal_assigned_blankets = optimal_assigned_blankets,\n",
    "                                     num_anchor_points = 100, \n",
    "                                     n_obs_t = None, \n",
    "                                     sample_anchor_points = sample_anchor_points,\n",
    "                                     controlled_experiment=True,\n",
    "                                     noise_experiment=False, \n",
    "                                     args_sem = [functions_0, functions_t],\n",
    "                                     manipulative_variables = ['F', 'X'] )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for s in range(0, 10):\n",
    "    n_replicates = 10\n",
    "    n_trials = 20\n",
    "    number_of_trials_BO_ABO = 20\n",
    "    folder = 'economic_data/seed_runs'\n",
    "    methods_list = ['DCBO', 'CBO', 'ABO', 'BO']\n",
    "    sample_anchor_points = True\n",
    "    cost_list = [1]\n",
    "    for cost in cost_list:\n",
    "        results = run_methods_replicates(Graph, \n",
    "                                         Real_SEM, \n",
    "                                         make_sem_real_hat, \n",
    "                                         intervention_domain, \n",
    "                                         methods_list = methods_list,\n",
    "                                         obs_samples = subset_obs_data,\n",
    "                                         ground_truth = GT,\n",
    "                                         exploration_sets = exploration_sets,\n",
    "                                         total_timesteps = T,\n",
    "                                         reps = n_replicates,\n",
    "                                         number_of_trials = n_trials, \n",
    "                                         number_of_trials_BO_ABO = number_of_trials_BO_ABO,\n",
    "                                         n_restart = 1,\n",
    "                                         save_data = True,\n",
    "                                         n_obs = None,                                    \n",
    "                                         hp_i_prior = True,\n",
    "                                         debug_mode = False,\n",
    "                                         folder = folder,\n",
    "                                         optimal_assigned_blankets = optimal_assigned_blankets,\n",
    "                                         num_anchor_points = 100, \n",
    "                                         n_obs_t = None, \n",
    "                                         sample_anchor_points = sample_anchor_points,\n",
    "                                         controlled_experiment=True,\n",
    "                                         noise_experiment=False, \n",
    "                                         args_sem = [functions_0, functions_t],\n",
    "                                         manipulative_variables = ['F', 'X'], \n",
    "                                         seed = s)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_replicates = 1\n",
    "number_of_interventions = None\n",
    "\n",
    "#pickle_off = open(\"../data/economic_data/method_DCBOCBOABOBO_T_3_it_30_reps_10_Nobs_None_online_False_concat_False_transfer_False_usedi_False_hpiprior_True_missing_False_noise_False.pickle\",\"rb\")\n",
    "pickle_off = open(\"../data/economic_data/no_blanket/method_DCBOCBOABOBO_T_3_it_30_reps_1_Nobs_None_online_False_concat_False_transfer_False_usedi_False_hpiprior_True_missing_False_noise_False.pickle\",\"rb\")\n",
    "\n",
    "data = pickle.load(pickle_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elaborate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import get_cumulative_cost_mean_and_std, extract_relevant_data_for_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(data, t_steps, repeats=5):\n",
    "    out = {key: [] for key in data.keys()}\n",
    "    for model in data.keys():\n",
    "        for t in range(t_steps):\n",
    "            tmp = []\n",
    "            for ex in range(repeats):\n",
    "                tmp.append(data[model][ex][t])\n",
    "            tmp = np.vstack(tmp)\n",
    "            out[model].append((tmp.mean(axis=0), tmp.std(axis=0)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if number_of_interventions is None:\n",
    "    for model in data.keys():\n",
    "        for r in range(n_replicates):\n",
    "            for t in range(T):\n",
    "                if data[model][r][1][t][0] == 10000000.0:\n",
    "                    data[model][r][1][t][0] = data[model][r][1][t][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data\n",
    "per_trial_cost = {model:[] for model in data.keys()}\n",
    "optimal_outcome_values_during_trials = {model:[] for model in data.keys()}\n",
    "\n",
    "for i in range(n_replicates):\n",
    "    for model in data.keys():\n",
    "        per_trial_cost[model].append(data[model][i][0])\n",
    "        optimal_outcome_values_during_trials[model].append(data[model][i][1])\n",
    "\n",
    "# Aggregate data\n",
    "exp_per_trial_cost = get_cumulative_cost_mean_and_std(per_trial_cost, T, repeats=n_replicates)\n",
    "exp_optimal_outcome_values_during_trials = get_mean_and_std(optimal_outcome_values_during_trials, T, repeats=n_replicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ABO and BO we make the cost start from 0 as in the competing models\n",
    "# We then augement the dimension of the y values to plot to ensure they can be plotted \n",
    "if 'BO' in  exp_per_trial_cost.keys() and 'ABO' in exp_per_trial_cost.keys():\n",
    "    initial_value_BO_ABO = np.max((exp_optimal_outcome_values_during_trials['BO'][0][0][0], exp_optimal_outcome_values_during_trials['ABO'][0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in exp_per_trial_cost.keys():\n",
    "    if model == 'BO' or model == 'ABO':\n",
    "        costs = exp_per_trial_cost[model]\n",
    "        values = exp_optimal_outcome_values_during_trials[model]\n",
    "        for t in range(T):\n",
    "            values_t = values[t]\n",
    "            exp_per_trial_cost[model][t] = np.asarray([0] + list(costs[t]))\n",
    "            exp_optimal_outcome_values_during_trials[model][t] = tuple([np.asarray([values_t[i][0]] + list(values_t[i])) for i in range(2)])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip values so they are not lower than the min\n",
    "clip_max = 1000\n",
    "for model in exp_per_trial_cost.keys():\n",
    "    for t in range(T):\n",
    "        clipped = np.clip(exp_optimal_outcome_values_during_trials[model][t][0], a_min = best_objective_values[t], a_max = clip_max)\n",
    "        exp_optimal_outcome_values_during_trials[model][t] = (clipped, exp_optimal_outcome_values_during_trials[model][t][1])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot convergence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "    \"linewidth\": 3,\n",
    "    \"linewidth_opt\": 4,\n",
    "    \"alpha\": 0.1,\n",
    "    \"xlim_max\": 20,\n",
    "    \"ncols\": 2,\n",
    "    \"loc_legend\": \"upper center\",\n",
    "    \"size_ticks\": 20,\n",
    "    \"size_labels\": 20,\n",
    "\n",
    "    \"labels\": {'DCBO': 'DCBO', 'CBO': 'CBO', 'ABO': 'ABO', 'BO': 'BO', 'True': '$\\mathbb{E}[Y_t| do(X_{st}^\\star = x_{st}^\\star)$'},\n",
    "    \"colors\": {'DCBO': 'blue', 'CBO': 'green', 'ABO': 'orange', 'BO': 'black', 'True': 'red'},\n",
    "    \"line_styles\": {'DCBO': '-', 'CBO': '--', 'ABO': 'dashdot', 'BO': '-', 'True': '-'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "cost = 1\n",
    "for t in range(T):\n",
    "    plot_expected_opt_curve(t,\n",
    "    best_objective_values[t],\n",
    "    exp_per_trial_cost,\n",
    "    exp_optimal_outcome_values_during_trials, \n",
    "    plot_params,\n",
    "    filename='time_{}_cost_{}_n_{}'.format(t,cost,n_replicates))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.08px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
